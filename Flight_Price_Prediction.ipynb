{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flight Price Prediction.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltNCBYsSOQGj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_kurnObOiWu"
      },
      "source": [
        "data = pd.read_excel(\"/content/Flight.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osh3unV3QGl0"
      },
      "source": [
        "pd.set_option(\"display.max_columns\",None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc7TDHpzO0zg"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNIC9o6BO2t4"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsVde3LjO7sR"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIJvvAi6PBLZ"
      },
      "source": [
        "data['Additional_Info'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-58MUIeaPGMs"
      },
      "source": [
        "data['Source'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7HgzbikPTH_"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS5aZa7jQSqN"
      },
      "source": [
        " data['Duration'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5ZHLUI9QSym"
      },
      "source": [
        "data.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiBpBtTTQS6m"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKs_YnX_QTCo"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y7M47KhQTK_"
      },
      "source": [
        "#EDA # data preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSFoSc2zQTTX"
      },
      "source": [
        "data['Journey_day'] = pd.to_datetime(data.Date_of_Journey, format = \"%d/%m/%Y\" ).dt.day\n",
        "data['Journey_month'] = pd.to_datetime(data.Date_of_Journey, format=\"%d/%m/%Y\").dt.month     #model will not be able to understand a string value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcjoLFvSQTbf"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV9bmDglQTjy"
      },
      "source": [
        "data.drop(['Date_of_Journey'], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H5r8gdpQTrx"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4q69KHVQT0I"
      },
      "source": [
        "data['Dep_Hour'] = pd.to_datetime(data['Dep_Time']).dt.hour\n",
        "data['Dep_min'] = pd.to_datetime(data['Dep_Time']).dt.minute\n",
        "data.drop([\"Dep_Time\"], axis = 1, inplace = True)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnEmEYCjQT77"
      },
      "source": [
        "data['Arrival_Hour'] = pd.to_datetime(data['Arrival_Time']).dt.hour\n",
        "data['Arrival_Min'] = pd.to_datetime(data['Arrival_Time']).dt.minute\n",
        "data.drop([\"Arrival_Time\"], axis = 1, inplace = True)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YuAoMsjQT5V"
      },
      "source": [
        "duration = list(data['Duration'])\n",
        "duration[4].strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lhGUYWnYJwI"
      },
      "source": [
        "duration_hours[0:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWC626TbQTxM"
      },
      "source": [
        "for i in range(len(duration)):\n",
        "    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n",
        "        if \"h\" in duration[i]:\n",
        "            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n",
        "        else:\n",
        "            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n",
        "\n",
        "duration_hours = []\n",
        "duration_mins = []\n",
        "for i in range(len(duration)):\n",
        "    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n",
        "    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUGvKkfUQTpE"
      },
      "source": [
        "data['Duration_hour'] = duration_hours\n",
        "data['DUration_mins'] = duration_mins\n",
        "data.drop(['Duration'], axis =1, inplace = True)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9XLldI4QTg5"
      },
      "source": [
        "#HANDLING CATEGORICAL DATA\n",
        "#Handling Categorical Data\n",
        "#One can find many ways to handle categorical data. Some of them categorical data are,\n",
        "\n",
        "#**Nominal data** --> data are not in any order --> **OneHotEncoder** is used in this case)         (STATES,COUNTRIES)\n",
        "#**Ordinal data** --> data are in order --> **LabelEncoder** is used in this case                   (GENDER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHRXoQXlQTYw"
      },
      "source": [
        "data['Airline'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahD3mcUfQTQh"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2mP_RTHQTIX"
      },
      "source": [
        "sns.catplot(y = \"Price\", x = \"Airline\", data = data.sort_values(\"Price\", ascending = False), kind=\"boxen\", height = 6, aspect = 3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WynzcQe4QTAA"
      },
      "source": [
        "#One hot encoding\n",
        "airline = data['Airline']\n",
        "airline = pd.get_dummies(airline,drop_first=True)\n",
        "airline.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVBdnTk9QS39"
      },
      "source": [
        "data['Source'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD4iEn2nc6f3"
      },
      "source": [
        "sns.catplot(y = \"Price\", x = \"Source\", data = data.sort_values(\"Price\", ascending = False), kind=\"boxen\", height = 4, aspect = 3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pKrrKWEc6n_"
      },
      "source": [
        "# As Source is Nominal Categorical data we will perform OneHotEncoding\n",
        "Source = data[[\"Source\"]]\n",
        "Source = pd.get_dummies(Source, drop_first= True)\n",
        "Source.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXQXc33Uc6vk"
      },
      "source": [
        "data['Destination'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pUsS-cuc63R"
      },
      "source": [
        "destination = data['Destination']\n",
        "destination = pd.get_dummies(destination, drop_first = True)\n",
        "destination.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3FsG9Tqc6_3"
      },
      "source": [
        "data['Route']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8a6mTzRc7IS"
      },
      "source": [
        "# Additional_Info contains almost 80% no_info\n",
        "# Route and Total_Stops are related to each other\n",
        "data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiIK38A-c7Qq"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZEzhGA0c7ZI"
      },
      "source": [
        "data['Total_Stops'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i8ShkcZc7V8"
      },
      "source": [
        "# As this is case of Ordinal Categorical type we perform LabelEncoder\n",
        "# Here Values are assigned with corresponding keys\n",
        "data.replace({\"non-stop\":0, \"1 stop\":1,  \"2 stops\": 2, \"3 stops\":3, \"4 stops\":4 }, inplace = True)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdPA_xNZc7N0"
      },
      "source": [
        "data = pd.concat([data, airline, Source, destination], axis = 1)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-gZwRIlc7Fl"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk0Ju6FDc681"
      },
      "source": [
        "data.drop([\"Airline\", \"Source\", \"Destination\"], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F2DeyhSc60q"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0RhH-Iyc6s-"
      },
      "source": [
        "#We have to do train and test data preprocessing differently because of data leakage, the model may be knowing information about test data.(Overfitting problems)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohGIeMZZgxpw"
      },
      "source": [
        "test_data = pd.read_excel(\"/content/Test_set.xlsx\")\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwNdbzj7gyGn"
      },
      "source": [
        "test_data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wea0kPJTgyYG"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "print(\"Test data Info\")\n",
        "print(\"-\"*75)\n",
        "print(test_data.info())\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"Null values :\")\n",
        "print(\"-\"*75)\n",
        "test_data.dropna(inplace = True)\n",
        "print(test_data.isnull().sum())\n",
        "# EDA\n",
        "\n",
        "# Date_of_Journey\n",
        "test_data[\"Journey_day\"] = pd.to_datetime(test_data.Date_of_Journey, format=\"%d/%m/%Y\").dt.day\n",
        "test_data[\"Journey_month\"] = pd.to_datetime(test_data[\"Date_of_Journey\"], format = \"%d/%m/%Y\").dt.month\n",
        "test_data.drop([\"Date_of_Journey\"], axis = 1, inplace = True)\n",
        "\n",
        "# Dep_Time\n",
        "test_data[\"Dep_hour\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.hour\n",
        "test_data[\"Dep_min\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.minute\n",
        "test_data.drop([\"Dep_Time\"], axis = 1, inplace = True)\n",
        "\n",
        "# Arrival_Time\n",
        "test_data[\"Arrival_hour\"] = pd.to_datetime(test_data.Arrival_Time).dt.hour\n",
        "test_data[\"Arrival_min\"] = pd.to_datetime(test_data.Arrival_Time).dt.minute\n",
        "test_data.drop([\"Arrival_Time\"], axis = 1, inplace = True)\n",
        "\n",
        "# Duration\n",
        "duration = list(test_data[\"Duration\"])\n",
        "\n",
        "for i in range(len(duration)):\n",
        "    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n",
        "        if \"h\" in duration[i]:\n",
        "            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n",
        "        else:\n",
        "            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n",
        "\n",
        "duration_hours = []\n",
        "duration_mins = []\n",
        "for i in range(len(duration)):\n",
        "    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n",
        "    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration\n",
        "\n",
        "# Adding Duration column to test set\n",
        "test_data[\"Duration_hours\"] = duration_hours\n",
        "test_data[\"Duration_mins\"] = duration_mins\n",
        "test_data.drop([\"Duration\"], axis = 1, inplace = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDQXddJggyga"
      },
      "source": [
        "# Categorical data\n",
        "\n",
        "print(\"Airline\")\n",
        "print(\"-\"*75)\n",
        "print(test_data[\"Airline\"].value_counts())\n",
        "Airline = pd.get_dummies(test_data[\"Airline\"], drop_first= True)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Source\")\n",
        "print(\"-\"*75)\n",
        "print(test_data[\"Source\"].value_counts())\n",
        "Source = pd.get_dummies(test_data[\"Source\"], drop_first= True)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Destination\")\n",
        "print(\"-\"*75)\n",
        "print(test_data[\"Destination\"].value_counts())\n",
        "Destination = pd.get_dummies(test_data[\"Destination\"], drop_first = True)\n",
        "\n",
        "# Additional_Info contains almost 80% no_info\n",
        "# Route and Total_Stops are related to each other\n",
        "test_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)\n",
        "\n",
        "# Replacing Total_Stops\n",
        "test_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)\n",
        "\n",
        "# Concatenate dataframe --> test_data + Airline + Source + Destination\n",
        "data_test = pd.concat([test_data, Airline, Source, Destination], axis = 1)\n",
        "\n",
        "data_test.drop([\"Airline\", \"Source\", \"Destination\"], axis = 1, inplace = True)\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"Shape of test data : \", data_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2UZEg6Ggydy"
      },
      "source": [
        "data_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyaaIiUVgyVG"
      },
      "source": [
        "data_train = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H47MnIhZgyMQ"
      },
      "source": [
        "print(\"Training dataset shape\",data_train.shape)\n",
        "print(\"Test data shape\",data_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfT2tobOkBJh"
      },
      "source": [
        "data_train.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndfEPr-ygyDr"
      },
      "source": [
        "X = data_train.loc[:, ['Total_Stops', 'Journey_day', 'Journey_month', 'Dep_Hour',\n",
        "       'Dep_min', 'Arrival_Hour', 'Arrival_Min', 'Duration_hour',\n",
        "       'DUration_mins', 'Air India', 'GoAir', 'IndiGo', 'Jet Airways',\n",
        "       'Jet Airways Business', 'Multiple carriers',\n",
        "       'Multiple carriers Premium economy', 'SpiceJet', 'Trujet', 'Vistara',\n",
        "       'Vistara Premium economy', 'Source_Chennai', 'Source_Delhi',\n",
        "       'Source_Kolkata', 'Source_Mumbai', 'Cochin', 'Delhi', 'Hyderabad',\n",
        "       'Kolkata', 'New Delhi']]\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igkY3Yf3gxmw"
      },
      "source": [
        "y = data_train.iloc[:, 1]\n",
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maa-hyY0c6mA"
      },
      "source": [
        "# Finds correlation between Independent and dependent attributes\n",
        "\n",
        "plt.figure(figsize = (18,18))\n",
        "sns.heatmap(data.corr(), annot = True, cmap = \"RdYlGn\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfvoPJYAQSvm"
      },
      "source": [
        "# Important feature using ExtraTreesRegressor\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "selection = ExtraTreesRegressor()\n",
        "selection.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNFFXbHzQSiH"
      },
      "source": [
        "print(selection.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skmw4Pezk-XP"
      },
      "source": [
        "#plot graph of feature importances for better visualization\n",
        "\n",
        "plt.figure(figsize = (12,8))\n",
        "feat_importances = pd.Series(selection.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(20).plot(kind='barh')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKsiJdaklDoU"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sR8X84ulOkS"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "reg_rf = RandomForestRegressor()\n",
        "reg_rf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmKU797RlQ5K"
      },
      "source": [
        "y_pred = reg_rf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOMCVjWGlUV3"
      },
      "source": [
        "reg_rf.score(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbF938pBlWYA"
      },
      "source": [
        "reg_rf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stMtgJ0QlbEr"
      },
      "source": [
        "sns.distplot(y_test-y_pred)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Joj5ZNMld51"
      },
      "source": [
        "plt.scatter(y_test, y_pred, alpha = 0.5)\n",
        "plt.xlabel(\"y_test\")\n",
        "plt.ylabel(\"y_pred\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJUm7F8slhCP"
      },
      "source": [
        "from sklearn import metrics\n",
        "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbpbxg_Pln3C"
      },
      "source": [
        "# RMSE/(max(DV)-min(DV))\n",
        "\n",
        "2090.5509/(max(y)-min(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFroWvw2lubb"
      },
      "source": [
        "metrics.r2_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXXUIdjOl_S2"
      },
      "source": [
        "#Hyperparameter Tuning\n",
        "#Choose following method for hyperparameter tuning\n",
        "#RandomizedSearchCV --> Fast\n",
        "#GridSearchCV\n",
        "#Assign hyperparameters in form of dictionery\n",
        "#Fit the model\n",
        "#Check best paramters and best score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK3cMPRdl_Zj"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL52Ppf_l_hi"
      },
      "source": [
        "#Randomized Search CV\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10, 15, 100]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 5, 10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VDIL0lXl_pX"
      },
      "source": [
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEnVLJ_Dl_x-"
      },
      "source": [
        "# Random search of parameters, using 5 fold cross validation, \n",
        "# search across 100 different combinations\n",
        "rf_random = RandomizedSearchCV(estimator = reg_rf, param_distributions = random_grid,scoring='neg_mean_squared_error', \n",
        "                               n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjyHlGXdl_7L"
      },
      "source": [
        "rf_random.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHGY3yi9l_3Y"
      },
      "source": [
        "rf_random.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpUSyLGDl_vZ"
      },
      "source": [
        "prediction = rf_random.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfKxkdenl_mp"
      },
      "source": [
        "plt.figure(figsize = (8,8))\n",
        "sns.distplot(y_test-prediction)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X2J92zfl_fe"
      },
      "source": [
        "plt.figure(figsize = (8,8))\n",
        "plt.scatter(y_test, prediction, alpha = 0.5)\n",
        "plt.xlabel(\"y_test\")\n",
        "plt.ylabel(\"y_pred\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQgVrcx-l_Ww"
      },
      "source": [
        "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqJo1sGQlwAT"
      },
      "source": [
        "import pickle\n",
        "# open a file, where you ant to store the data\n",
        "file = open('flight_rf.pkl', 'wb')\n",
        "\n",
        "# dump information to that file\n",
        "pickle.dump(reg_rf, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7t1Gd6MmsRg"
      },
      "source": [
        "model = open('flight_price_rf.pkl','rb')\n",
        "forest = pickle.load(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRA9FpcMmvpF"
      },
      "source": [
        "y_prediction = forest.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_hcxpz8mxIz"
      },
      "source": [
        "metrics.r2_score(y_test, y_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ0QyLBpmxel"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}